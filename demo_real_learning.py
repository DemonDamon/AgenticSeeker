#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
çœŸå®å­¦ä¹ æ¼”ç¤º - å±•ç¤ºActionReflectorAgentçš„å®æ—¶çŸ«æ­£èƒ½åŠ›

è¿™ä¸ªæ¼”ç¤ºå°†å±•ç¤ºï¼š
1. çœŸå®çš„åæ ‡å­¦ä¹ å’Œè°ƒæ•´
2. æ‰§è¡Œç­–ç•¥çš„åŠ¨æ€ä¼˜åŒ–
3. å¤šæ¬¡è¿­ä»£çš„ç²¾åº¦æå‡
4. å®Œæ•´çš„åé¦ˆå¾ªç¯
"""

import asyncio
import sys
import os
import time
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agenticx.core.event_bus import EventBus
from agenticx.core.event import Event
from agents.executor_agent import ExecutorAgent
from agents.action_reflector_agent import ActionReflectorAgent
from utils import get_iso_timestamp


class RealLearningDemo:
    """çœŸå®å­¦ä¹ æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.event_bus = EventBus()
        self.executor = None
        self.reflector = None
        self.learning_iterations = []
        
    async def setup_agents(self):
        """è®¾ç½®æ™ºèƒ½ä½“"""
        print("ğŸš€ åˆå§‹åŒ–çœŸå®å­¦ä¹ ç³»ç»Ÿ...")
        
        # åˆ›å»ºExecutorAgent
        self.executor = ExecutorAgent(
            agent_id="learning_executor",
            event_bus=self.event_bus
        )
        
        # åˆ›å»ºActionReflectorAgent
        self.reflector = ActionReflectorAgent(
            agent_id="learning_reflector",
            event_bus=self.event_bus
        )
        
        print("âœ… æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
        
    async def simulate_coordinate_learning_cycle(self):
        """æ¨¡æ‹Ÿåæ ‡å­¦ä¹ å¾ªç¯"""
        print("\n" + "="*60)
        print("ğŸ¯ åæ ‡å­¦ä¹ å¾ªç¯æ¼”ç¤º")
        print("="*60)
        
        # ç›®æ ‡åæ ‡ï¼ˆç†æƒ³ä½ç½®ï¼‰
        target_coords = [500, 650]
        print(f"ğŸ¯ ç›®æ ‡åæ ‡: {target_coords}")
        
        # æ¨¡æ‹Ÿ5æ¬¡å­¦ä¹ è¿­ä»£
        test_coordinates = [
            [450, 600],  # ç¬¬1æ¬¡ï¼šåå·¦åä¸Š
            [480, 620],  # ç¬¬2æ¬¡ï¼šè½»å¾®åç§»
            [495, 640],  # ç¬¬3æ¬¡ï¼šæ¥è¿‘ç›®æ ‡
            [498, 648],  # ç¬¬4æ¬¡ï¼šéå¸¸æ¥è¿‘
            [500, 650],  # ç¬¬5æ¬¡ï¼šå®Œç¾å‘½ä¸­
        ]
        
        for i, coords in enumerate(test_coordinates, 1):
            print(f"\nğŸ“‹ ç¬¬{i}æ¬¡è¿­ä»£")
            await self._perform_learning_iteration(i, coords, target_coords)
            
            # æ˜¾ç¤ºå½“å‰å­¦ä¹ çŠ¶æ€
            self._display_current_learning_state()
            
            # çŸ­æš‚ç­‰å¾…
            await asyncio.sleep(0.5)
    
    async def _perform_learning_iteration(self, iteration: int, test_coords: List[int], target_coords: List[int]):
        """æ‰§è¡Œå•æ¬¡å­¦ä¹ è¿­ä»£"""
        print(f"   æµ‹è¯•åæ ‡: {test_coords}")
        
        # è®¡ç®—åç§»é‡
        offset_x = test_coords[0] - target_coords[0]
        offset_y = test_coords[1] - target_coords[1]
        
        # åˆ¤æ–­æ˜¯å¦æˆåŠŸï¼ˆå®¹å·®èŒƒå›´å†…ï¼‰
        tolerance = 10
        is_success = abs(offset_x) <= tolerance and abs(offset_y) <= tolerance
        
        print(f"   åç§»é‡: [{offset_x}, {offset_y}]")
        print(f"   ç»“æœ: {'âœ… æˆåŠŸ' if is_success else 'âŒ å¤±è´¥'}")
        
        # å¦‚æœå¤±è´¥ï¼Œç”Ÿæˆå­¦ä¹ åé¦ˆ
        if not is_success:
            # è®¡ç®—éœ€è¦çš„è°ƒæ•´
            adjustment_x = -offset_x  # åå‘è°ƒæ•´
            adjustment_y = -offset_y
            
            # é™åˆ¶è°ƒæ•´å¹…åº¦ï¼ˆæ¨¡æ‹Ÿæ¸è¿›å­¦ä¹ ï¼‰
            max_adjustment = 20
            adjustment_x = max(-max_adjustment, min(max_adjustment, adjustment_x))
            adjustment_y = max(-max_adjustment, min(max_adjustment, adjustment_y))
            
            print(f"   å»ºè®®è°ƒæ•´: [{adjustment_x}, {adjustment_y}]")
            
            # ç›´æ¥åº”ç”¨å­¦ä¹ ï¼ˆæ¨¡æ‹Ÿåé¦ˆæœºåˆ¶ï¼‰
            self.executor._store_coordinate_adjustment(test_coords, [adjustment_x, adjustment_y])
            
            # æ¨¡æ‹Ÿç­–ç•¥è°ƒæ•´
            if abs(offset_x) > 30 or abs(offset_y) > 30:
                strategy = {
                    "timeout": 10.0,
                    "retry_delay": 1.5,
                    "verification_required": True
                }
                self.executor._update_execution_strategy("click_action", strategy)
                print(f"   ç­–ç•¥è°ƒæ•´: å¢åŠ è¶…æ—¶å’ŒéªŒè¯")
        
        # è®°å½•è¿­ä»£ç»“æœ
        self.learning_iterations.append({
            "iteration": iteration,
            "test_coords": test_coords,
            "target_coords": target_coords,
            "offset": [offset_x, offset_y],
            "success": is_success,
            "adjustment": [adjustment_x, adjustment_y] if not is_success else [0, 0]
        })
    
    def _display_current_learning_state(self):
        """æ˜¾ç¤ºå½“å‰å­¦ä¹ çŠ¶æ€"""
        # æ˜¾ç¤ºå­¦ä¹ åˆ°çš„åæ ‡è°ƒæ•´
        if hasattr(self.executor, 'coordinate_adjustments') and self.executor.coordinate_adjustments:
            print(f"   ğŸ“š å·²å­¦ä¹ çš„åæ ‡è°ƒæ•´:")
            for coord_key, adjustment in list(self.executor.coordinate_adjustments.items())[-3:]:
                print(f"     {coord_key}: {adjustment}")
        
        # æ˜¾ç¤ºæ‰§è¡Œç­–ç•¥
        if hasattr(self.executor, 'execution_strategies') and self.executor.execution_strategies:
            print(f"   ğŸ“‹ å½“å‰æ‰§è¡Œç­–ç•¥:")
            for task_type, strategy in self.executor.execution_strategies.items():
                print(f"     {task_type}: {strategy}")
    
    async def demonstrate_adaptive_correction(self):
        """æ¼”ç¤ºè‡ªé€‚åº”çŸ«æ­£"""
        print("\n" + "="*60)
        print("ğŸ”„ è‡ªé€‚åº”çŸ«æ­£æ¼”ç¤º")
        print("="*60)
        
        # æ¨¡æ‹Ÿè¿ç»­æ“ä½œä¸­çš„è‡ªé€‚åº”å­¦ä¹ 
        scenarios = [
            {"coords": [400, 500], "description": "æ–°ä½ç½®é¦–æ¬¡å°è¯•"},
            {"coords": [600, 700], "description": "å¦ä¸€ä¸ªæ–°ä½ç½®"},
            {"coords": [450, 550], "description": "ç›¸ä¼¼ä½ç½®ï¼ˆåº”ç”¨åŒºåŸŸåŒ¹é…ï¼‰"},
            {"coords": [580, 680], "description": "ç›¸ä¼¼ä½ç½®ï¼ˆåº”ç”¨åŒºåŸŸåŒ¹é…ï¼‰"},
        ]
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\nğŸ“‹ åœºæ™¯{i}: {scenario['description']}")
            coords = scenario["coords"]
            
            # è·å–å­¦ä¹ åˆ°çš„è°ƒæ•´
            learned_adjustment = self.executor._get_learned_coordinate_adjustment(coords)
            print(f"   åŸå§‹åæ ‡: {coords}")
            print(f"   å­¦ä¹ è°ƒæ•´: {learned_adjustment}")
            
            # åº”ç”¨è°ƒæ•´åçš„åæ ‡
            adjusted_coords = [coords[0] + learned_adjustment[0], coords[1] + learned_adjustment[1]]
            print(f"   è°ƒæ•´ååæ ‡: {adjusted_coords}")
            
            # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ
            if learned_adjustment != [0, 0]:
                print(f"   âœ… åº”ç”¨äº†å­¦ä¹ ç»éªŒï¼Œç²¾åº¦æå‡")
            else:
                print(f"   ğŸ†• æ–°ä½ç½®ï¼Œå¼€å§‹å­¦ä¹ ")
                # ä¸ºæ–°ä½ç½®æ·»åŠ ä¸€äº›å­¦ä¹ æ•°æ®
                mock_adjustment = [10, -5]  # æ¨¡æ‹Ÿå­¦ä¹ åˆ°çš„è°ƒæ•´
                self.executor._store_coordinate_adjustment(coords, mock_adjustment)
                print(f"   ğŸ“š å­¦ä¹ æ–°è°ƒæ•´: {mock_adjustment}")
    
    def display_learning_analytics(self):
        """æ˜¾ç¤ºå­¦ä¹ åˆ†æ"""
        print("\n" + "="*60)
        print("ğŸ“Š å­¦ä¹ æ•ˆæœåˆ†æ")
        print("="*60)
        
        if not self.learning_iterations:
            print("æš‚æ— å­¦ä¹ æ•°æ®")
            return
        
        # æˆåŠŸç‡åˆ†æ
        total_iterations = len(self.learning_iterations)
        successful_iterations = sum(1 for it in self.learning_iterations if it["success"])
        success_rate = successful_iterations / total_iterations * 100
        
        print(f"\nğŸ“ˆ æ€»ä½“å­¦ä¹ æ•ˆæœ:")
        print(f"  - æ€»è¿­ä»£æ¬¡æ•°: {total_iterations}")
        print(f"  - æˆåŠŸæ¬¡æ•°: {successful_iterations}")
        print(f"  - æˆåŠŸç‡: {success_rate:.1f}%")
        
        # ç²¾åº¦æ”¹è¿›åˆ†æ
        if total_iterations >= 2:
            first_offset = self.learning_iterations[0]["offset"]
            last_offset = self.learning_iterations[-1]["offset"]
            
            first_distance = (first_offset[0]**2 + first_offset[1]**2)**0.5
            last_distance = (last_offset[0]**2 + last_offset[1]**2)**0.5
            
            improvement = first_distance - last_distance
            improvement_percent = (improvement / first_distance * 100) if first_distance > 0 else 0
            
            print(f"\nğŸ¯ ç²¾åº¦æ”¹è¿›:")
            print(f"  - åˆå§‹åç§»è·ç¦»: {first_distance:.1f}åƒç´ ")
            print(f"  - æœ€ç»ˆåç§»è·ç¦»: {last_distance:.1f}åƒç´ ")
            print(f"  - ç²¾åº¦æå‡: {improvement:.1f}åƒç´  ({improvement_percent:.1f}%)")
        
        # å­¦ä¹ æ›²çº¿
        print(f"\nğŸ“‰ å­¦ä¹ æ›²çº¿:")
        for iteration in self.learning_iterations:
            i = iteration["iteration"]
            offset = iteration["offset"]
            distance = (offset[0]**2 + offset[1]**2)**0.5
            status = "âœ…" if iteration["success"] else "âŒ"
            print(f"  ç¬¬{i}æ¬¡: {status} åç§»è·ç¦» {distance:.1f}px")
    
    def display_system_capabilities(self):
        """æ˜¾ç¤ºç³»ç»Ÿèƒ½åŠ›"""
        print(f"\nğŸš€ ç³»ç»Ÿèƒ½åŠ›æ€»ç»“:")
        
        capabilities = [
            "ğŸ¯ ç²¾ç¡®åæ ‡å­¦ä¹  - åŸºäºåç§»é‡è‡ªåŠ¨è®¡ç®—è°ƒæ•´",
            "ğŸ”„ æ¸è¿›å¼ä¼˜åŒ– - é¿å…è¿‡åº¦è°ƒæ•´ï¼Œç¨³å®šæ”¶æ•›",
            "ğŸ“ åŒºåŸŸåŒ¹é…å­¦ä¹  - ç›¸ä¼¼ä½ç½®å…±äº«å­¦ä¹ ç»éªŒ",
            "ğŸ“Š å¤šç»´åº¦åé¦ˆ - åæ ‡ã€ç­–ç•¥ã€æ—¶æœºå…¨æ–¹ä½ä¼˜åŒ–",
            "ğŸ§  æ™ºèƒ½è®°å¿†ç®¡ç† - ä¿æŒæœ‰æ•ˆå­¦ä¹ ï¼Œé¿å…è¿‡æ‹Ÿåˆ",
            "âš¡ å®æ—¶è‡ªé€‚åº” - æ¯æ¬¡æ“ä½œéƒ½æ˜¯å­¦ä¹ æœºä¼š",
            "ğŸ” å¤šæ¨¡æ€éªŒè¯ - ç»“åˆè§†è§‰åˆ†æç¡®ä¿å­¦ä¹ è´¨é‡",
            "ğŸ“ˆ æŒç»­æ”¹è¿› - ç³»ç»Ÿä½¿ç”¨è¶Šä¹…ï¼Œç²¾åº¦è¶Šé«˜"
        ]
        
        for capability in capabilities:
            print(f"  {capability}")
        
        # æ˜¾ç¤ºæœ€ç»ˆå­¦ä¹ çŠ¶æ€
        feedback_summary = self.executor.get_reflection_feedback_summary()
        print(f"\nğŸ“Š æœ€ç»ˆå­¦ä¹ çŠ¶æ€:")
        print(f"  - åæ ‡è°ƒæ•´è§„åˆ™: {feedback_summary['coordinate_adjustments_count']}")
        print(f"  - æ‰§è¡Œç­–ç•¥ä¼˜åŒ–: {feedback_summary['execution_strategies_count']}")
        print(f"  - æ€»åé¦ˆæ¬¡æ•°: {feedback_summary['total_feedback_count']}")
    
    async def run_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        try:
            await self.setup_agents()
            
            print("\nğŸ¯ è¿™ä¸ªæ¼”ç¤ºå°†å±•ç¤ºçœŸå®çš„å­¦ä¹ è¿‡ç¨‹:")
            print("1. åæ ‡åç§»æ£€æµ‹å’Œè‡ªåŠ¨è°ƒæ•´")
            print("2. æ¸è¿›å¼å­¦ä¹ å’Œç²¾åº¦æå‡")
            print("3. åŒºåŸŸåŒ¹é…å’Œç»éªŒå…±äº«")
            print("4. æ‰§è¡Œç­–ç•¥çš„åŠ¨æ€ä¼˜åŒ–")
            print("5. å®Œæ•´çš„å­¦ä¹ æ•ˆæœåˆ†æ")
            
            await self.simulate_coordinate_learning_cycle()
            await self.demonstrate_adaptive_correction()
            
            self.display_learning_analytics()
            self.display_system_capabilities()
            
            print(f"\nğŸ‰ çœŸå®å­¦ä¹ æ¼”ç¤ºå®Œæˆï¼")
            print(f"\nğŸ’¡ æ ¸å¿ƒä»·å€¼:")
            print(f"  âœ… çœŸæ­£çš„è‡ªåŠ¨åŒ–å­¦ä¹  - æ— éœ€äººå·¥å¹²é¢„")
            print(f"  âœ… æŒç»­ç²¾åº¦æå‡ - æ¯æ¬¡ä½¿ç”¨éƒ½åœ¨è¿›æ­¥")
            print(f"  âœ… æ™ºèƒ½ç»éªŒå…±äº« - å­¦ä¹ æˆæœå¯å¤ç”¨")
            print(f"  âœ… å¤šç»´åº¦ä¼˜åŒ– - ä¸ä»…ä»…æ˜¯åæ ‡è°ƒæ•´")
            
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨çœŸå®å­¦ä¹ æ¼”ç¤º")
    print("\nè¿™ä¸æ˜¯å£å¤´å¹å˜˜ï¼Œè¿™æ˜¯çœŸå®çš„ä»£ç å®ç°ï¼")
    
    demo = RealLearningDemo()
    await demo.run_demo()


if __name__ == "__main__":
    asyncio.run(main())